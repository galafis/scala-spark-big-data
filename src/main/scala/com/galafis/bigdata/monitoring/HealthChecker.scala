package com.galafis.bigdata.monitoring

import org.apache.spark.sql.SparkSession

/**
 * ðŸ‡§ðŸ‡· Verificador de saÃºde do cluster Spark e do pipeline
 * ðŸ‡ºðŸ‡¸ Spark cluster and pipeline health checker
 */
object HealthChecker {

  def isClusterHealthy(spark: SparkSession): Boolean = {
    spark.sparkContext.statusTracker.getExecutorInfos.length > 0
  }

  def checkDataPath(path: String): Boolean = {
    val file = new java.io.File(path)
    file.exists() && file.canRead
  }
}
