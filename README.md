# Scala Spark Big Data

![Hero Image](images/hero_image.jpg)

## üáßüá∑ Portugu√™s

[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Scala](https://img.shields.io/badge/Scala-2.12-blue.svg)](https://www.scala-lang.org/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.3.0-orange.svg)](https://spark.apache.org/)
[![sbt](https://img.shields.io/badge/sbt-1.x-green.svg)](https://www.scala-sbt.org/)

Este reposit√≥rio apresenta um projeto de processamento de Big Data utilizando Scala e Apache Spark. O projeto demonstra a implementa√ß√£o de pipelines de ETL, an√°lise de dados em lote e em tempo real, e a constru√ß√£o de modelos de machine learning para detec√ß√£o de fraude e segmenta√ß√£o de clientes.

### Funcionalidades

*   **Processamento de Dados em Lote (Batch Processing)**: Ingest√£o, transforma√ß√£o e carregamento de grandes volumes de dados transacionais.
*   **Processamento de Dados em Tempo Real (Streaming Processing)**: An√°lise de fluxos de dados para detec√ß√£o de anomalias e agrega√ß√µes em tempo real.
*   **An√°lise de Dados e Machine Learning**: Implementa√ß√£o de algoritmos de machine learning para detec√ß√£o de fraude, segmenta√ß√£o de clientes, an√°lise de s√©ries temporais e an√°lise de cesta de compras.
*   **Estrutura Modular**: C√≥digo organizado em m√≥dulos para facilitar a manuten√ß√£o e escalabilidade.
*   **Configura√ß√£o Flex√≠vel**: Utiliza√ß√£o de arquivos de configura√ß√£o para gerenciar par√¢metros da aplica√ß√£o e do Spark.

### Tecnologias Utilizadas

*   **Scala**: Linguagem de programa√ß√£o principal.
*   **Apache Spark**: Framework unificado para processamento de Big Data.
*   **Delta Lake**: Camada de armazenamento de dados para data lakes.
*   **sbt**: Ferramenta de constru√ß√£o para projetos Scala.
*   **Apache Hadoop (AWS S3)**: Integra√ß√£o com armazenamento em nuvem.
*   **Logback**: Sistema de logging.
*   **ScalaTest & Mockito**: Frameworks para testes unit√°rios.

### Estrutura do Projeto

```
scala-spark-big-data/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scala/com/galafis/bigdata/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ analytics/        # L√≥gica de an√°lise e ML
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ apps/             # Aplica√ß√µes principais
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ core/             # Componentes centrais
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ etl/              # Pipelines de Extra√ß√£o, Transforma√ß√£o e Carga
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ models/           # Defini√ß√µes de modelos de dados
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ monitoring/       # Ferramentas de monitoramento
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ storage/          # Camadas de abstra√ß√£o de armazenamento
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ streaming/        # L√≥gica de processamento de streaming
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils/            # Fun√ß√µes utilit√°rias
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/             # Testes unit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ integration/      # Testes de integra√ß√£o
‚îú‚îÄ‚îÄ config/               # Arquivos de configura√ß√£o da aplica√ß√£o
‚îú‚îÄ‚îÄ data/                 # Dados de exemplo ou mock
‚îú‚îÄ‚îÄ docs/                 # Documenta√ß√£o adicional, diagramas
‚îú‚îÄ‚îÄ images/               # Imagens e elementos visuais
‚îú‚îÄ‚îÄ notebooks/            # Notebooks Jupyter/Zeppelin para explora√ß√£o
‚îú‚îÄ‚îÄ project/              # Configura√ß√µes do sbt
‚îú‚îÄ‚îÄ build.sbt             # Defini√ß√µes de build do sbt
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îú‚îÄ‚îÄ README_EN.md          # Vers√£o em ingl√™s deste arquivo
‚îú‚îÄ‚îÄ LICENSE               # Licen√ßa do projeto
‚îî‚îÄ‚îÄ CONTRIBUTING.md       # Guia de contribui√ß√£o
```

### Como Usar

#### Pr√©-requisitos

*   Java Development Kit (JDK) 8 ou superior
*   sbt (Scala Build Tool)
*   Apache Spark (para execu√ß√£o em cluster, opcional para `local[*]`) 

#### Constru√ß√£o do Projeto

Para construir o projeto, navegue at√© o diret√≥rio raiz e execute:

```bash
sbt clean compile
```

#### Execu√ß√£o dos Testes

Para executar os testes unit√°rios e de integra√ß√£o:

```bash
sbt test
```

Para gerar o relat√≥rio de cobertura de c√≥digo:

```bash
sbt coverageReport
```

#### Execu√ß√£o da Aplica√ß√£o

O projeto pode ser executado em diferentes modos: `batch`, `streaming` ou `analytics`.

**Modo Batch:**

```bash
sbt "run batch"
```

**Modo Streaming:**

```bash
sbt "run streaming"
```

**Modo Analytics:**

```bash
sbt "run analytics"
```

### Diagrama de Arquitetura

```mermaid
graph TD
    A[Fonte de Dados]
    B(Ingest√£o de Dados)
    C{Processamento ETL}
    D[Data Lake (Delta Lake)]
    E(Processamento em Lote)
    F(Processamento em Streaming)
    G[Modelos de ML & An√°lises]
    H[Detec√ß√£o de Anomalias em Tempo Real]
    I[Resultados & Dashboards]
    J[Usu√°rios/Aplica√ß√µes]

    A --> B
    B --> C
    C --> D
    D --> E
    D --> F
    E --> G
    F --> H
    G --> I
    H --> I
    I --> J

    subgraph Apache Spark
        C
        E
        F
        G
        H
    end

    subgraph AWS S3
        D
    end

    subgraph Aplica√ß√£o Scala
        A
        B
        I
        J
    end
```

### Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Por favor, leia o `CONTRIBUTING.md` para detalhes sobre como submeter pull requests.

### Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo `LICENSE` para detalhes.

### Autor

**Gabriel Demetrios Lafis**

*   [GitHub](https://github.com/galafis)
*   [LinkedIn](https://www.linkedin.com/in/gabriel-demetrios-lafis/)

